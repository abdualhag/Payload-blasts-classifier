{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from shutil import copyfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'avgpool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-615d92000493>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 535\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'avgpool'"
     ]
    }
   ],
   "source": [
    "#Classify only using GPU\n",
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = image.convert('RGB')\n",
    "    image = loader(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = Variable(image)\n",
    "    return image\n",
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "events_path = './run175'\n",
    "\n",
    "i = 0\n",
    "for event in os.listdir(events_path):\n",
    "    if event.endswith(\".png\"): \n",
    "        event_path = events_path + \"/\" + event\n",
    "        pred_agrees = 1\n",
    "        for i in range(6):\n",
    "            if i == 0: model_name = \"vgg\"\n",
    "            if i == 1: model_name = \"alexnet\"\n",
    "            if i == 2: model_name = \"resnet\"\n",
    "            if i == 3: model_name = \"densenet\"\n",
    "            if i == 4: model_name = \"squeezenet\"   \n",
    "            if i == 5:\n",
    "                model_name = \"inception\"   \n",
    "                input_size = 299\n",
    "            model = torch.load(\"./\" + model_name + \".pt\")\n",
    "            model.eval()\n",
    "            model.cpu()\n",
    "            \n",
    "            prediction = model(image_loader(data_transforms, event_path)) \n",
    "            prediction = prediction.data.numpy().argmax()\n",
    "            if (prediction == 1): \n",
    "                pred_agrees *= 2\n",
    "        \n",
    "    if (pred_agrees >= 64): \n",
    "        copyfile(event_path, './test/payload' + event)\n",
    "    else:\n",
    "        copyfile(event_path, './test/noise/' + event) \n",
    "        i += 1\n",
    "    if  (i > 5000): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'VGG' object has no attribute 'avgpool'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5a7bd3e6eba0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_loader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_transforms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 535\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'VGG' object has no attribute 'avgpool'"
     ]
    }
   ],
   "source": [
    "#Classify only using GPU\n",
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = image.convert('RGB')\n",
    "    image = loader(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = Variable(image)\n",
    "    return image.cuda()\n",
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "events_path = './run175'\n",
    "\n",
    "i = 0\n",
    "for event in os.listdir(events_path):\n",
    "    if event.endswith(\".png\"): \n",
    "        event_path = events_path + \"/\" + event\n",
    "        pred_agrees = 1\n",
    "        for i in range(6):\n",
    "            if i == 0: model_name = \"vgg\"\n",
    "            if i == 1: model_name = \"alexnet\"\n",
    "            if i == 2: model_name = \"resnet\"\n",
    "            if i == 3: model_name = \"densenet\"\n",
    "            if i == 4: model_name = \"squeezenet\"   \n",
    "            if i == 5:\n",
    "                model_name = \"inception\"   \n",
    "                input_size = 299\n",
    "            model = torch.load(\"./\" + model_name + \".pt\")\n",
    "            model.eval()\n",
    "            \n",
    "            prediction = model(image_loader(data_transforms, event_path)) \n",
    "            prediction = int(prediction.argmax())\n",
    "            if (prediction == 1): \n",
    "                pred_agrees *= 2\n",
    "        \n",
    "    if (pred_agrees >= 64): \n",
    "        copyfile(event_path, './test/payload' + event)\n",
    "    else:\n",
    "        copyfile(event_path, './test/noise/' + event) \n",
    "        i += 1\n",
    "    if  (i > 5000): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify only using GPU\n",
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = image.convert('RGB')\n",
    "    image = loader(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = Variable(image)\n",
    "    return image.cuda()\n",
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "events_path = './run175'\n",
    "\n",
    "for i in range(6):\n",
    "    if i == 0: model_name = \"vgg\"\n",
    "    if i == 1: model_name = \"alexnet\"\n",
    "    if i == 2: model_name = \"resnet\"\n",
    "    if i == 3: model_name = \"densenet\"\n",
    "    if i == 4: model_name = \"squeezenet\"   \n",
    "    if i == 5:\n",
    "        model_name = \"inception\"   \n",
    "        input_size = 299\n",
    "    model = torch.load(\"./\" + model_name + \".pt\")\n",
    "    model.eval()\n",
    "\n",
    "    for event in os.listdir(events_path):\n",
    "        if event.endswith(\".png\"): \n",
    "            event_path = events_path + \"/\" + event\n",
    "            prediction = model(image_loader(data_transforms, event_path)) \n",
    "            prediction = int(prediction.argmax())\n",
    "            if (prediction == 1): \n",
    "                copyfile(event_path, './events/payload/' + model_name + '/' + event)\n",
    "            else: \n",
    "                copyfile(event_path, './events/noise/' + model_name + '/' + event)                \n",
    "    print (model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify only using CPU\n",
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = image.convert('RGB')\n",
    "    image = loader(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = Variable(image)\n",
    "    return image\n",
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "events_path = './run175'\n",
    "\n",
    "for i in range(6):\n",
    "    if i == 0: model_name = \"vgg\"\n",
    "    if i == 1: model_name = \"alexnet\"\n",
    "    if i == 2: model_name = \"resnet\"\n",
    "    if i == 3: model_name = \"densenet\"\n",
    "    if i == 4: model_name = \"squeezenet\"   \n",
    "    if i == 5:\n",
    "        model_name = \"inception\"   \n",
    "        input_size = 299\n",
    "    model = torch.load(\"./\" + model_name + \".pt\")\n",
    "    model.eval()\n",
    "    model.cpu()\n",
    "\n",
    "    for event in os.listdir(events_path):\n",
    "        if event.endswith(\".png\"): \n",
    "            event_path = events_path + \"/\" + event\n",
    "            prediction = model(image_loader(data_transforms, event_path)) \n",
    "            prediction = prediction.data.numpy().argmax()\n",
    "            #print (event, prediction)\n",
    "            if (prediction == 1): \n",
    "                copyfile(event_path, './events/payload/' + model_name + '/' + event)\n",
    "            else: \n",
    "                copyfile(event_path, './events/noise/' + model_name + '/' + event)\n",
    "    print (model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_diff():\n",
    "    folder1 = os.listdir(PATH1) # folder containing your files\n",
    "    folder2 = os.listdir(PATH2) # the other folder\n",
    "    folder3 = os.listdir(PATH3) # the other folder\n",
    "    folder4 = os.listdir(PATH4) # the other folder\n",
    "    folder5 = os.listdir(PATH5) # the other folder\n",
    "    folder6 = os.listdir(PATH6) # the other folder\n",
    "    brk = False\n",
    "    for item1 in folder1:\n",
    "        for item2 in folder2:\n",
    "            for item3 in folder3:\n",
    "                for item4 in folder4:\n",
    "                    for item5 in folder5:\n",
    "                        for item6 in folder6:\n",
    "                            if(item1 == item2 == item3 == item4 == item5 == item6):\n",
    "                                #print (item1[:(len(item1) - 4)])\n",
    "                                copyfile(PATH1 + item1, './events/payload/' + 'shared/' + item1)\n",
    "                                brk = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_diff():\n",
    "    folder1 = os.listdir(PATH5) # folder containing your files\n",
    "    folder2 = os.listdir(PATH6) # the other folder\n",
    "\n",
    "    for item1 in folder1:\n",
    "        for item2 in folder2:\n",
    "            if(item1 == item2):\n",
    "                #print (item1[:(len(item1) - 4)])\n",
    "                copyfile(PATH5 + item1, './events/payload/' + 'alexnet-densenet/' + item1)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder_diff():\n",
    "    folder1 = os.listdir(PATH7) # folder containing your files\n",
    "    folder2 = os.listdir(PATH8) # the other folder\n",
    "    folder3 = os.listdir(PATH9) # the other folder\n",
    "\n",
    "    for item1 in folder1:\n",
    "        for item2 in folder2:\n",
    "            for item3 in folder3:\n",
    "                if(item1 == item2 == item3):\n",
    "                    #print (item1[:(len(item1) - 4)])\n",
    "                    copyfile(PATH7 + item1, './events/payload/' + 'shared/' + item1)\n",
    "                    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files():\n",
    "    folder1 = os.listdir(PATH1) # folder containing your files\n",
    "    for item1 in folder1:\n",
    "         print (item1[:(len(item1) - 4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH1 = './events/payload/vgg/'\n",
    "PATH2 = './events/payload/resnet/'\n",
    "PATH3 = './events/payload/squeezenet/'\n",
    "PATH4 = './events/payload/inception/'\n",
    "PATH5 = './events/payload/alexnet/'\n",
    "PATH6 = './events/payload/densenet/'\n",
    "PATH7 = './events/payload/vgg-resnet/'\n",
    "PATH8 = './events/payload/alexnet-densenet/'\n",
    "PATH9 = './events/payload/inception-squeezenet/'\n",
    "\n",
    "PATH = './events/'\n",
    "#list_files()\n",
    "folder_diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./\" + \"vgg\" + \".pt\")\n",
    "model.eval()\n",
    "\n",
    "prediction = model(image_loader(data_transforms, \"./4Isb3u5.png\")) \n",
    "\n",
    "\n",
    "print (int(prediction.argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classify only using one model\n",
    "\n",
    "def image_loader(loader, image_name):\n",
    "    image = Image.open(image_name)\n",
    "    image = image.convert('RGB')\n",
    "    image = loader(image)\n",
    "    image = image.unsqueeze(0)\n",
    "    image = Variable(image)\n",
    "    return image.cuda()\n",
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.CenterCrop(input_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "events_path = './run175'\n",
    "since = time.time()\n",
    "for i in range(6):\n",
    "    if i == 1:\n",
    "        if i == 0: model_name = \"vgg\"\n",
    "        if i == 1: model_name = \"alexnet\"\n",
    "        if i == 2: model_name = \"resnet\"\n",
    "        if i == 3: model_name = \"densenet\"\n",
    "        if i == 4: model_name = \"squeezenet\"   \n",
    "        if i == 5:\n",
    "            model_name = \"inception\"   \n",
    "            input_size = 299\n",
    "        model = torch.load(\"./\" + model_name + \".pt\")\n",
    "        model.eval()\n",
    "\n",
    "        for event in os.listdir(events_path):\n",
    "            if event.endswith(\".png\"): \n",
    "                event_path = events_path + \"/\" + event\n",
    "                prediction = model(image_loader(data_transforms, event_path)) \n",
    "                prediction = int(prediction.argmax())\n",
    "                if (prediction == 1): \n",
    "                    copyfile(event_path, './events/payload/' + model_name + '/' + event)              \n",
    "        print (model_name)\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "directory = './run175/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.png'):\n",
    "        try:\n",
    "            img = Image.open(directory + filename) # open the image file\n",
    "            #img.verify() # verify that it is, in fact an image\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            print('Bad file:', filename) # print out the names of corrupt files\n",
    "            copyfile(directory + filename, './corrupted/' + filename)\n",
    "            os.remove(directory + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if files in range\n",
    "events_path = './payload'\n",
    "\n",
    "\n",
    "for event in os.listdir(events_path):\n",
    "    if event.endswith(\".png\"): \n",
    "        event_path = events_path + \"/\" + event\n",
    "        eventName = event.strip(\".png\")\n",
    "        if (int(eventName) >= 15374101 and int(eventName) <= 15381949): \n",
    "            copyfile(event_path, './DustinRun175/' + event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean file names in directory\n",
    "events_path = './Dustin/run175_maybe'\n",
    "\n",
    "\n",
    "for event in os.listdir(events_path):\n",
    "    if event.endswith(\".png\"): \n",
    "        event_path = events_path + \"/\" + event\n",
    "        eventName = event.replace(\"run175_event\", \"\")\n",
    "        copyfile(event_path, './Dustin/Run175Maybe/' + eventName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if files in range\n",
    "events_path = './Dustin/Run175/'\n",
    "dustin_path = './DustinRun175/'\n",
    "\n",
    "for event in os.listdir(events_path):\n",
    "    if event.endswith(\".png\"): \n",
    "        event_path = events_path + event\n",
    "        if (not(os.path.isfile(dustin_path + event))): \n",
    "            copyfile(event_path, dustin_path + 'Not/' + event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
